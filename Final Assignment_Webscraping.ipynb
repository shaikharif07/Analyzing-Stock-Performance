{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "    <img src=\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/Images/SN_logo.png\" width=\"300\" alt=\"cognitiveclass.ai logo\"  />\n",
    "</center>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Extracting Stock Data Using a Web Scraping</h1>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not all stock data is available via API in this assignment; you will use web-scraping to obtain financial data. You will be quizzed on your results.\\\n",
    "Using beautiful soup we will extract historical share data from a web-page.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>\n",
    "<div class=\"alert alert-block alert-info\" style=\"margin-top: 20px\">\n",
    "    <ul>\n",
    "        <li>Downloading the Webpage Using Requests Library</li>\n",
    "        <li>Parsing Webpage HTML Using BeautifulSoup</li>\n",
    "        <li>Extracting Data and Building DataFrame</li>\n",
    "    </ul>\n",
    "<p>\n",
    "    Estimated Time Needed: <strong>30 min</strong></p>\n",
    "</div>\n",
    "\n",
    "<hr>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pandas==1.3.3\n",
      "  Downloading pandas-1.3.3-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.3/11.3 MB\u001b[0m \u001b[31m63.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: python-dateutil>=2.7.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas==1.3.3) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2017.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas==1.3.3) (2022.6)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from pandas==1.3.3) (1.21.6)\n",
      "Requirement already satisfied: six>=1.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from python-dateutil>=2.7.3->pandas==1.3.3) (1.16.0)\n",
      "Installing collected packages: pandas\n",
      "  Attempting uninstall: pandas\n",
      "    Found existing installation: pandas 1.3.5\n",
      "    Uninstalling pandas-1.3.5:\n",
      "      Successfully uninstalled pandas-1.3.5\n",
      "Successfully installed pandas-1.3.3\n",
      "Collecting requests==2.26.0\n",
      "  Downloading requests-2.26.0-py2.py3-none-any.whl (62 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.3/62.3 kB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: certifi>=2017.4.17 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests==2.26.0) (2022.9.24)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests==2.26.0) (1.26.13)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from requests==2.26.0) (3.4)\n",
      "Collecting charset-normalizer~=2.0.0\n",
      "  Downloading charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
      "Installing collected packages: charset-normalizer, requests\n",
      "  Attempting uninstall: charset-normalizer\n",
      "    Found existing installation: charset-normalizer 2.1.1\n",
      "    Uninstalling charset-normalizer-2.1.1:\n",
      "      Successfully uninstalled charset-normalizer-2.1.1\n",
      "  Attempting uninstall: requests\n",
      "    Found existing installation: requests 2.28.1\n",
      "    Uninstalling requests-2.28.1:\n",
      "      Successfully uninstalled requests-2.28.1\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "ibm-cos-sdk-core 2.12.0 requires requests<3.0,>=2.27.1, but you have requests 2.26.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed charset-normalizer-2.0.12 requests-2.26.0\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['bs4==4.10.0']\n",
      "\n",
      "pkgs/r/linux-64          [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.20 KB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.20 KB/s)\n",
      "pkgs/main/linux-64       [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.20 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.20 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [=>                ] (00m:00s) 495  B / ?? (3.20 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.43 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 495  B / ?? (3.20 KB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.43 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.43 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.43 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) \n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [=>                ] (00m:00s) 748 KB / ?? (2.43 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 752 KB / ?? (2.44 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 752 KB / ?? (2.44 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/main/noarch         [<=>                 ] (00m:00s) Done\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 752 KB / ?? (2.44 MB/s)\n",
      "pkgs/main/noarch         [====================] (00m:00s) Done\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/r/noarch            [=>                ] (00m:00s) 752 KB / ?? (2.44 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) Finalizing...\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/r/noarch            [<=>                 ] (00m:00s) Done\n",
      "pkgs/r/noarch            [====================] (00m:00s) Done\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [=>                ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [<=>               ] (00m:00s) 660 KB / ?? (2.14 MB/s)\n",
      "pkgs/r/linux-64          [<=>               ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/r/linux-64          [ <=>              ] (00m:00s) 684 KB / ?? (2.22 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/r/linux-64          [  <=>               ] (00m:00s) 1 MB / ?? (2.85 MB/s)\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/r/linux-64          [  <=>               ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/r/linux-64          [  <=>               ] (00m:00s) Done\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/r/linux-64          [====================] (00m:00s) Done\n",
      "pkgs/main/linux-64       [ <=>                ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 1 MB / ?? (3.14 MB/s)\n",
      "pkgs/main/linux-64       [  <=>               ] (00m:00s) 2 MB / ?? (3.52 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 2 MB / ?? (3.52 MB/s)\n",
      "pkgs/main/linux-64       [   <=>              ] (00m:00s) 3 MB / ?? (3.78 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 3 MB / ?? (3.78 MB/s)\n",
      "pkgs/main/linux-64       [    <=>             ] (00m:00s) 4 MB / ?? (4.01 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) 4 MB / ?? (4.01 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) 4 MB / ?? (4.20 MB/s)\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) Finalizing...\n",
      "pkgs/main/linux-64       [     <=>            ] (00m:00s) Done\n",
      "pkgs/main/linux-64       [====================] (00m:00s) Done\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - bs4==4.10.0\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package               Version  Build           Channel                  Size\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + bs4            \u001b[00m      4.10.0  hd3eb1b0_0      pkgs/main/noarch        10 KB\n",
      "\n",
      "  Change:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - openssl        \u001b[00m      1.1.1s  h0b41bf4_1      installed                    \n",
      "\u001b[32m  + openssl        \u001b[00m      1.1.1s  h7f8727e_0      pkgs/main/linux-64       4 MB\n",
      "\n",
      "  Upgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - ca-certificates\u001b[00m   2022.9.24  ha878542_0      installed                    \n",
      "\u001b[32m  + ca-certificates\u001b[00m  2022.10.11  h06a4308_0      pkgs/main/linux-64     124 KB\n",
      "\u001b[31m  - certifi        \u001b[00m   2022.9.24  pyhd8ed1ab_0    installed                    \n",
      "\u001b[32m  + certifi        \u001b[00m   2022.12.7  py37h06a4308_0  pkgs/main/linux-64     150 KB\n",
      "\n",
      "  Downgrade:\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[31m  - beautifulsoup4 \u001b[00m      4.11.1  pyha770c72_0    installed                    \n",
      "\u001b[32m  + beautifulsoup4 \u001b[00m      4.10.0  pyh06a4308_0    pkgs/main/noarch        85 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 1 packages\n",
      "  Change: 1 packages\n",
      "  Upgrade: 2 packages\n",
      "  Downgrade: 1 packages\n",
      "\n",
      "  Total download: 4 MB\n",
      "\n",
      "────────────────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [>                                        ] (00m:00s)    3.41 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)    3.41 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   65.40 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished bs4                                  (00m:00s)              10 KB     65 KB/s\n",
      "Downloading  [>                                        ] (00m:00s)   65.40 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   65.40 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   65.40 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [>                                        ] (00m:00s)   65.40 KB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [=>                                       ] (00m:00s)  986.59 KB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "\u001b[2A\u001b[0KFinished certifi                              (00m:00s)             150 KB    924 KB/s\n",
      "Downloading  [=>                                       ] (00m:00s)  986.59 KB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [=>                                       ] (00m:00s)  986.59 KB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [=>                                       ] (00m:00s)  986.59 KB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [==>                                      ] (00m:00s)    1.46 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "\u001b[2A\u001b[0KFinished beautifulsoup4                       (00m:00s)              85 KB    514 KB/s\n",
      "Downloading  [==>                                      ] (00m:00s)    1.46 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [==>                                      ] (00m:00s)    1.46 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    2.17 MB/s\n",
      "Extracting   [========>                                ] (00m:00s)        1 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    2.17 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    2.17 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "\u001b[2A\u001b[0KFinished ca-certificates                      (00m:00s)             124 KB    753 KB/s\n",
      "Downloading  [===>                                     ] (00m:00s)    2.17 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [===>                                     ] (00m:00s)    2.17 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [================>                        ] (00m:00s)        2 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "\u001b[2A\u001b[0KFinished openssl                              (00m:00s)               4 MB     20 MB/s\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [========================>                ] (00m:00s)        3 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [================================>        ] (00m:00s)        4 / 5\n",
      "Downloading  [=========================================] (00m:00s)   22.08 MB/s\n",
      "Extracting   [=========================================] (00m:00s)        5 / 5\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "\n",
      "                  __    __    __    __\n",
      "                 /  \\  /  \\  /  \\  /  \\\n",
      "                /    \\/    \\/    \\/    \\\n",
      "███████████████/  /██/  /██/  /██/  /████████████████████████\n",
      "              /  / \\   / \\   / \\   / \\  \\____\n",
      "             /  /   \\_/   \\_/   \\_/   \\    o \\__,\n",
      "            / _/                       \\_____/  `\n",
      "            |/\n",
      "        ███╗   ███╗ █████╗ ███╗   ███╗██████╗  █████╗\n",
      "        ████╗ ████║██╔══██╗████╗ ████║██╔══██╗██╔══██╗\n",
      "        ██╔████╔██║███████║██╔████╔██║██████╔╝███████║\n",
      "        ██║╚██╔╝██║██╔══██║██║╚██╔╝██║██╔══██╗██╔══██║\n",
      "        ██║ ╚═╝ ██║██║  ██║██║ ╚═╝ ██║██████╔╝██║  ██║\n",
      "        ╚═╝     ╚═╝╚═╝  ╚═╝╚═╝     ╚═╝╚═════╝ ╚═╝  ╚═╝\n",
      "\n",
      "        mamba (0.15.3) supported by @QuantStack\n",
      "\n",
      "        GitHub:  https://github.com/mamba-org/mamba\n",
      "        Twitter: https://twitter.com/QuantStack\n",
      "\n",
      "█████████████████████████████████████████████████████████████\n",
      "\n",
      "\n",
      "Looking for: ['html5lib==1.1']\n",
      "\n",
      "pkgs/main/linux-64       Using cache\n",
      "pkgs/main/noarch         Using cache\n",
      "pkgs/r/linux-64          Using cache\n",
      "pkgs/r/noarch            Using cache\n",
      "\n",
      "Pinned packages:\n",
      "  - python 3.7.*\n",
      "\n",
      "\n",
      "Transaction\n",
      "\n",
      "  Prefix: /home/jupyterlab/conda/envs/python\n",
      "\n",
      "  Updating specs:\n",
      "\n",
      "   - html5lib==1.1\n",
      "   - ca-certificates\n",
      "   - certifi\n",
      "   - openssl\n",
      "\n",
      "\n",
      "  Package         Version  Build         Channel                 Size\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "  Install:\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "\u001b[32m  + html5lib    \u001b[00m      1.1  pyhd3eb1b0_0  pkgs/main/noarch       91 KB\n",
      "\u001b[32m  + webencodings\u001b[00m    0.5.1  py37_1        pkgs/main/linux-64     19 KB\n",
      "\n",
      "  Summary:\n",
      "\n",
      "  Install: 2 packages\n",
      "\n",
      "  Total download: 110 KB\n",
      "\n",
      "───────────────────────────────────────────────────────────────────────\n",
      "\n",
      "Downloading  [======>                                  ] (00m:00s)  136.39 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "\u001b[2A\u001b[0KFinished webencodings                         (00m:00s)              19 KB    136 KB/s\n",
      "Downloading  [======>                                  ] (00m:00s)  136.39 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  136.39 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [======>                                  ] (00m:00s)  136.39 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  758.05 KB/s\n",
      "Extracting   [>                                                      ] (--:--) \n",
      "Downloading  [=========================================] (00m:00s)  758.05 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "\u001b[2A\u001b[0KFinished html5lib                             (00m:00s)              91 KB    623 KB/s\n",
      "Downloading  [=========================================] (00m:00s)  758.05 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  758.05 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  758.05 KB/s\n",
      "Extracting   [====================>                    ] (00m:00s)        1 / 2\n",
      "Downloading  [=========================================] (00m:00s)  758.05 KB/s\n",
      "Extracting   [=========================================] (00m:00s)        2 / 2\n",
      "Preparing transaction: done\n",
      "Verifying transaction: done\n",
      "Executing transaction: done\n",
      "Collecting lxml==4.6.4\n",
      "  Downloading lxml-4.6.4-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.manylinux_2_24_x86_64.whl (6.3 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m72.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: lxml\n",
      "  Attempting uninstall: lxml\n",
      "    Found existing installation: lxml 4.9.1\n",
      "    Uninstalling lxml-4.9.1:\n",
      "      Successfully uninstalled lxml-4.9.1\n",
      "Successfully installed lxml-4.6.4\n",
      "Collecting plotly==5.3.1\n",
      "  Downloading plotly-5.3.1-py2.py3-none-any.whl (23.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m23.9/23.9 MB\u001b[0m \u001b[31m53.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: six in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from plotly==5.3.1) (1.16.0)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /home/jupyterlab/conda/envs/python/lib/python3.7/site-packages (from plotly==5.3.1) (8.1.0)\n",
      "Installing collected packages: plotly\n",
      "  Attempting uninstall: plotly\n",
      "    Found existing installation: plotly 5.11.0\n",
      "    Uninstalling plotly-5.11.0:\n",
      "      Successfully uninstalled plotly-5.11.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "dash 2.7.0 requires dash-core-components==2.0.0, which is not installed.\n",
      "dash 2.7.0 requires dash-html-components==2.0.0, which is not installed.\n",
      "dash 2.7.0 requires dash-table==5.0.0, which is not installed.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed plotly-5.3.1\n"
     ]
    }
   ],
   "source": [
    "!pip install pandas==1.3.3\n",
    "!pip install requests==2.26.0\n",
    "!mamba install bs4==4.10.0 -y\n",
    "!mamba install html5lib==1.1 -y\n",
    "!pip install lxml==4.6.4\n",
    "!pip install plotly==5.3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Webscraping to Extract Stock Data Example\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we must use the `request` library to downlaod the webpage, and extract the text. We will extract Netflix stock data <https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html>.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'requests' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_69/625742084.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0murl\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\" https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'requests' is not defined"
     ]
    }
   ],
   "source": [
    "# url = \"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\"\n",
    "\n",
    "# data  = requests.get(url).text\n",
    "\n",
    "url = \" https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/netflix_data_webpage.html\"\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we must parse the text into html using `beautiful_soup`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# soup = BeautifulSoup(data, 'html5lib')\n",
    "soup = BeautifulSoup(data, 'html5lib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can turn the html table into a pandas dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "netflix_data = pd.DataFrame(columns=[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"])\n",
    "\n",
    "# First we isolate the body of the table which contains all the information\n",
    "# Then we loop through each row and find all the column values for each row\n",
    "for row in soup.find(\"tbody\").find_all('tr'):\n",
    "    col = row.find_all(\"td\")\n",
    "    date = col[0].text\n",
    "    Open = col[1].text\n",
    "    high = col[2].text\n",
    "    low = col[3].text\n",
    "    close = col[4].text\n",
    "    adj_close = col[5].text\n",
    "    volume = col[6].text\n",
    "    \n",
    "    # Finally we append the data of each row to the table\n",
    "    netflix_data = netflix_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now print out the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jun 01, 2021</td>\n",
       "      <td>504.01</td>\n",
       "      <td>536.13</td>\n",
       "      <td>482.14</td>\n",
       "      <td>528.21</td>\n",
       "      <td>528.21</td>\n",
       "      <td>78,560,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 01, 2021</td>\n",
       "      <td>512.65</td>\n",
       "      <td>518.95</td>\n",
       "      <td>478.54</td>\n",
       "      <td>502.81</td>\n",
       "      <td>502.81</td>\n",
       "      <td>66,927,600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 01, 2021</td>\n",
       "      <td>529.93</td>\n",
       "      <td>563.56</td>\n",
       "      <td>499.00</td>\n",
       "      <td>513.47</td>\n",
       "      <td>513.47</td>\n",
       "      <td>111,573,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mar 01, 2021</td>\n",
       "      <td>545.57</td>\n",
       "      <td>556.99</td>\n",
       "      <td>492.85</td>\n",
       "      <td>521.66</td>\n",
       "      <td>521.66</td>\n",
       "      <td>90,183,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb 01, 2021</td>\n",
       "      <td>536.79</td>\n",
       "      <td>566.65</td>\n",
       "      <td>518.28</td>\n",
       "      <td>538.85</td>\n",
       "      <td>538.85</td>\n",
       "      <td>61,902,300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low   Close Adj Close       Volume\n",
       "0  Jun 01, 2021  504.01  536.13  482.14  528.21    528.21   78,560,600\n",
       "1  May 01, 2021  512.65  518.95  478.54  502.81    502.81   66,927,600\n",
       "2  Apr 01, 2021  529.93  563.56  499.00  513.47    513.47  111,573,300\n",
       "3  Mar 01, 2021  545.57  556.99  492.85  521.66    521.66   90,183,900\n",
       "4  Feb 01, 2021  536.79  566.65  518.28  538.85    538.85   61,902,300"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the pandas `read_html` function using the url\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "No tables found",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_703/2733926450.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mread_html_pandas_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_html\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/util/_decorators.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    309\u001b[0m                     \u001b[0mstacklevel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstacklevel\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    310\u001b[0m                 )\n\u001b[0;32m--> 311\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    312\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mread_html\u001b[0;34m(io, match, flavor, header, index_col, skiprows, attrs, parse_dates, thousands, encoding, decimal, converters, na_values, keep_default_na, displayed_only)\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mna_values\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mna_values\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mkeep_default_na\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeep_default_na\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1113\u001b[0;31m         \u001b[0mdisplayed_only\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdisplayed_only\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1114\u001b[0m     )\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    925\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mretained\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m  \u001b[0;31m# for mypy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 926\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mretained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    927\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m     \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse\u001b[0;34m(flavor, io, match, attrs, encoding, displayed_only, **kwargs)\u001b[0m\n\u001b[1;32m    904\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 906\u001b[0;31m             \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    907\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mValueError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcaught\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    908\u001b[0m             \u001b[0;31m# if `io` is an io-like object, check if it's seekable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36mparse_tables\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    220\u001b[0m         \u001b[0mlist\u001b[0m \u001b[0mof\u001b[0m \u001b[0mparsed\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfooter\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0mtuples\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m         \"\"\"\n\u001b[0;32m--> 222\u001b[0;31m         \u001b[0mtables\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_tables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_build_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_parse_thead_tbody_tfoot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtable\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/conda/envs/python/lib/python3.7/site-packages/pandas/io/html.py\u001b[0m in \u001b[0;36m_parse_tables\u001b[0;34m(self, doc, match, attrs)\u001b[0m\n\u001b[1;32m    550\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mtables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 552\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"No tables found\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    553\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    554\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: No tables found"
     ]
    }
   ],
   "source": [
    "read_html_pandas_data = pd.read_html(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Or we can convert the BeautifulSoup object to a string\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "read_html_pandas_data = pd.read_html(str(soup))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Beacause there is only one table on the page, we just take the first table in the list returned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close*</th>\n",
       "      <th>Adj Close**</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jun 01, 2021</td>\n",
       "      <td>504.01</td>\n",
       "      <td>536.13</td>\n",
       "      <td>482.14</td>\n",
       "      <td>528.21</td>\n",
       "      <td>528.21</td>\n",
       "      <td>78560600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>May 01, 2021</td>\n",
       "      <td>512.65</td>\n",
       "      <td>518.95</td>\n",
       "      <td>478.54</td>\n",
       "      <td>502.81</td>\n",
       "      <td>502.81</td>\n",
       "      <td>66927600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Apr 01, 2021</td>\n",
       "      <td>529.93</td>\n",
       "      <td>563.56</td>\n",
       "      <td>499.00</td>\n",
       "      <td>513.47</td>\n",
       "      <td>513.47</td>\n",
       "      <td>111573300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mar 01, 2021</td>\n",
       "      <td>545.57</td>\n",
       "      <td>556.99</td>\n",
       "      <td>492.85</td>\n",
       "      <td>521.66</td>\n",
       "      <td>521.66</td>\n",
       "      <td>90183900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Feb 01, 2021</td>\n",
       "      <td>536.79</td>\n",
       "      <td>566.65</td>\n",
       "      <td>518.28</td>\n",
       "      <td>538.85</td>\n",
       "      <td>538.85</td>\n",
       "      <td>61902300</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date    Open    High     Low  Close* Adj Close**     Volume\n",
       "0  Jun 01, 2021  504.01  536.13  482.14  528.21      528.21   78560600\n",
       "1  May 01, 2021  512.65  518.95  478.54  502.81      502.81   66927600\n",
       "2  Apr 01, 2021  529.93  563.56  499.00  513.47      513.47  111573300\n",
       "3  Mar 01, 2021  545.57  556.99  492.85  521.66      521.66   90183900\n",
       "4  Feb 01, 2021  536.79  566.65  518.28  538.85      538.85   61902300"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_dataframe = read_html_pandas_data[0]\n",
    "\n",
    "netflix_dataframe.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Webscraping to Extract Stock Data Exercise\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the `requests` library to download the webpage <https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/amazon_data_webpage.html>. Save the text of the response as a variable named `html_data`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "url =\"https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0220EN-SkillsNetwork/labs/project/amazon_data_webpage.html\"\n",
    "\n",
    "data = requests.get(url).text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parse the html data using `beautiful_soup`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "soup = BeautifulSoup(data, 'html5lib')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 1</b> What is the content of the title attribute:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<title>Amazon.com, Inc. (AMZN) Stock Historical Prices &amp; Data - Yahoo Finance</title>"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.title"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using beautiful soup extract the table with historical share prices and store it into a dataframe named `amazon_data`. The dataframe should have columns Date, Open, High, Low, Close, Adj Close, and Volume. Fill in each variable with the correct data from the list `col`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# netflix_data = pd.DataFrame(columns=[\"Date\", \"Open\", \"High\", \"Low\", \"Close\", \"Volume\"])\n",
    "amazon_data = pd.DataFrame(columns=[\"Date\",\"Open\",\"High\",\"Low\",\"Close\",\"Adj Close\",\"Volume\"])\n",
    "\n",
    "# First we isolate the body of the table which contains all the information\n",
    "# Then we loop through each row and find all the column values for each row\n",
    "for row in soup.find(\"tbody\").find_all('tr'):\n",
    "    col = row.find_all(\"td\")\n",
    "    date = col[0].text\n",
    "    Open = col[1].text\n",
    "    high = col[2].text\n",
    "    low = col[3].text\n",
    "    close = col[4].text\n",
    "    adj_close = col[5].text\n",
    "    volume = col[6].text\n",
    "    \n",
    "    # Finally we append the data of each row to the table\n",
    "    amazon_data = amazon_data.append({\"Date\":date, \"Open\":Open, \"High\":high, \"Low\":low, \"Close\":close, \"Adj Close\":adj_close, \"Volume\":volume}, ignore_index=True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print out the first five rows of the `amazon_data` dataframe you created.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Jan 01, 2021</td>\n",
       "      <td>3,270.00</td>\n",
       "      <td>3,363.89</td>\n",
       "      <td>3,086.00</td>\n",
       "      <td>3,206.20</td>\n",
       "      <td>3,206.20</td>\n",
       "      <td>71,528,900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 01, 2020</td>\n",
       "      <td>3,188.50</td>\n",
       "      <td>3,350.65</td>\n",
       "      <td>3,072.82</td>\n",
       "      <td>3,256.93</td>\n",
       "      <td>3,256.93</td>\n",
       "      <td>77,556,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Nov 01, 2020</td>\n",
       "      <td>3,061.74</td>\n",
       "      <td>3,366.80</td>\n",
       "      <td>2,950.12</td>\n",
       "      <td>3,168.04</td>\n",
       "      <td>3,168.04</td>\n",
       "      <td>90,810,500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Oct 01, 2020</td>\n",
       "      <td>3,208.00</td>\n",
       "      <td>3,496.24</td>\n",
       "      <td>3,019.00</td>\n",
       "      <td>3,036.15</td>\n",
       "      <td>3,036.15</td>\n",
       "      <td>116,226,100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Sep 01, 2020</td>\n",
       "      <td>3,489.58</td>\n",
       "      <td>3,552.25</td>\n",
       "      <td>2,871.00</td>\n",
       "      <td>3,148.73</td>\n",
       "      <td>3,148.73</td>\n",
       "      <td>115,899,300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Aug 01, 2020</td>\n",
       "      <td>3,180.51</td>\n",
       "      <td>3,495.00</td>\n",
       "      <td>3,073.00</td>\n",
       "      <td>3,450.96</td>\n",
       "      <td>3,450.96</td>\n",
       "      <td>83,516,600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date      Open      High       Low     Close Adj Close       Volume\n",
       "0  Jan 01, 2021  3,270.00  3,363.89  3,086.00  3,206.20  3,206.20   71,528,900\n",
       "1  Dec 01, 2020  3,188.50  3,350.65  3,072.82  3,256.93  3,256.93   77,556,200\n",
       "2  Nov 01, 2020  3,061.74  3,366.80  2,950.12  3,168.04  3,168.04   90,810,500\n",
       "3  Oct 01, 2020  3,208.00  3,496.24  3,019.00  3,036.15  3,036.15  116,226,100\n",
       "4  Sep 01, 2020  3,489.58  3,552.25  2,871.00  3,148.73  3,148.73  115,899,300\n",
       "5  Aug 01, 2020  3,180.51  3,495.00  3,073.00  3,450.96  3,450.96   83,516,600"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.head(6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 2</b> What is the name of the columns of the dataframe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Date', 'Open', 'High', 'Low', 'Close', 'Adj Close', 'Volume'], dtype='object')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_data.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Question 3</b> What is the `Open` of the last row of the amazon_data dataframe?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60    656.29\n",
       "Name: Open, dtype: object"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ab = amazon_data.tail(1)\n",
    "ab[\"Open\"]\n",
    "\n",
    "# amazon_data.tail(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/?utm_medium=Exinfluencer&utm_source=Exinfluencer&utm_content=000026UJ&utm_term=10006555&utm_id=NA-SkillsNetwork-Channel-SkillsNetworkCoursesIBMDeveloperSkillsNetworkPY0220ENSkillsNetwork900-2022-01-01\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD.\n",
    "\n",
    "Azim Hirjani\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Change Log\n",
    "\n",
    "| Date (YYYY-MM-DD) | Version | Changed By | Change Description |\n",
    "| ----------------- | ------- | ---------- | ------------------ |\n",
    "\n",
    "```\n",
    "| 2021-06-09       | 1.2     | Lakshmi Holla|Added URL in question 3 |\n",
    "```\n",
    "\n",
    "\\| 2020-11-10        | 1.1     | Malika Singla | Deleted the Optional part |\n",
    "\\| 2020-08-27        | 1.0     | Malika Singla | Added lab to GitLab       |\n",
    "\n",
    "<hr>\n",
    "\n",
    "## <h3 align=\"center\"> © IBM Corporation 2020. All rights reserved. <h3/>\n",
    "\n",
    "<p>\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python",
   "language": "python",
   "name": "conda-env-python-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
